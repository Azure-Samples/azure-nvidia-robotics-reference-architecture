"""
Annotation Pydantic models for robotic episode annotation system.

These models match the TypeScript type definitions and PRD schema specifications
for task completeness, trajectory quality, data quality, and anomaly annotations.
"""

from datetime import datetime
from enum import Enum

from pydantic import BaseModel, Field

# ============================================================================
# Task Completeness Types
# ============================================================================


class TaskCompletenessRating(str, Enum):
    """Task completion status rating."""

    SUCCESS = "success"
    PARTIAL = "partial"
    FAILURE = "failure"
    UNKNOWN = "unknown"


class ConfidenceLevel(int, Enum):
    """Annotator confidence level (1-5 scale)."""

    ONE = 1
    TWO = 2
    THREE = 3
    FOUR = 4
    FIVE = 5


class TaskCompletenessAnnotation(BaseModel):
    """Task completeness annotation with rating and optional details."""

    rating: TaskCompletenessRating
    confidence: ConfidenceLevel
    completion_percentage: int | None = Field(None, ge=0, le=100)
    failure_reason: str | None = None
    subtask_reached: str | None = None

    model_config = {"use_enum_values": True}


# ============================================================================
# Trajectory Quality Types
# ============================================================================


class QualityScore(int, Enum):
    """Quality score on a 1-5 scale."""

    ONE = 1
    TWO = 2
    THREE = 3
    FOUR = 4
    FIVE = 5


class TrajectoryFlag(str, Enum):
    """Flags indicating specific trajectory issues."""

    JITTERY = "jittery"
    INEFFICIENT_PATH = "inefficient-path"
    NEAR_COLLISION = "near-collision"
    OVER_EXTENSION = "over-extension"
    UNDER_REACHING = "under-reaching"
    HESITATION = "hesitation"
    CORRECTION_HEAVY = "correction-heavy"


class TrajectoryQualityMetrics(BaseModel):
    """Individual trajectory quality metrics."""

    smoothness: QualityScore
    efficiency: QualityScore
    safety: QualityScore
    precision: QualityScore

    model_config = {"use_enum_values": True}


class TrajectoryQualityAnnotation(BaseModel):
    """Complete trajectory quality annotation."""

    overall_score: QualityScore
    metrics: TrajectoryQualityMetrics
    flags: list[TrajectoryFlag] = Field(default_factory=list)

    model_config = {"use_enum_values": True}


# ============================================================================
# Data Quality Types
# ============================================================================


class DataQualityLevel(str, Enum):
    """Overall data quality level."""

    GOOD = "good"
    ACCEPTABLE = "acceptable"
    POOR = "poor"
    UNUSABLE = "unusable"


class DataQualityIssueType(str, Enum):
    """Types of data quality issues."""

    FRAME_DROP = "frame-drop"
    SYNC_ISSUE = "sync-issue"
    OCCLUSION = "occlusion"
    LIGHTING_ISSUE = "lighting-issue"
    SENSOR_NOISE = "sensor-noise"
    CALIBRATION_DRIFT = "calibration-drift"
    ENCODING_ARTIFACT = "encoding-artifact"
    MISSING_DATA = "missing-data"


class IssueSeverity(str, Enum):
    """Severity of a data quality issue."""

    MINOR = "minor"
    MAJOR = "major"
    CRITICAL = "critical"


class DataQualityIssue(BaseModel):
    """Individual data quality issue."""

    type: DataQualityIssueType
    severity: IssueSeverity
    affected_frames: tuple[int, int] | None = None
    affected_streams: list[str] | None = None
    notes: str | None = None

    model_config = {"use_enum_values": True}


class DataQualityAnnotation(BaseModel):
    """Complete data quality annotation."""

    overall_quality: DataQualityLevel
    issues: list[DataQualityIssue] = Field(default_factory=list)

    model_config = {"use_enum_values": True}


# ============================================================================
# Anomaly Types
# ============================================================================


class AnomalySeverity(str, Enum):
    """Severity of an anomaly."""

    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"


class AnomalyType(str, Enum):
    """Types of anomalies that can be detected."""

    UNEXPECTED_STOP = "unexpected-stop"
    TRAJECTORY_DEVIATION = "trajectory-deviation"
    FORCE_SPIKE = "force-spike"
    VELOCITY_SPIKE = "velocity-spike"
    OBJECT_SLIP = "object-slip"
    GRIPPER_FAILURE = "gripper-failure"
    COLLISION = "collision"
    OTHER = "other"


class Anomaly(BaseModel):
    """Individual anomaly marker."""

    id: str
    type: AnomalyType
    severity: AnomalySeverity
    frame_range: tuple[int, int]
    timestamp: tuple[float, float]
    description: str
    auto_detected: bool = False
    verified: bool = False

    model_config = {"use_enum_values": True}


class AnomalyAnnotation(BaseModel):
    """Container for anomaly annotations."""

    anomalies: list[Anomaly] = Field(default_factory=list)


# ============================================================================
# Combined Episode Annotation Types
# ============================================================================


class EpisodeAnnotation(BaseModel):
    """Complete annotation for a single episode by one annotator."""

    annotator_id: str
    timestamp: datetime
    task_completeness: TaskCompletenessAnnotation
    trajectory_quality: TrajectoryQualityAnnotation
    data_quality: DataQualityAnnotation
    anomalies: AnomalyAnnotation
    notes: str | None = None


class EpisodeConsensus(BaseModel):
    """Consensus annotation derived from multiple annotators."""

    task_completeness: TaskCompletenessRating
    trajectory_score: float = Field(ge=1.0, le=5.0)
    data_quality: DataQualityLevel
    agreement_score: float = Field(ge=0.0, le=1.0)

    model_config = {"use_enum_values": True}


class EpisodeAnnotationFile(BaseModel):
    """Complete annotation file for an episode."""

    schema_version: str = "1.0.0"
    episode_index: int = Field(ge=0)
    dataset_id: str
    annotations: list[EpisodeAnnotation] = Field(default_factory=list)
    consensus: EpisodeConsensus | None = None


# ============================================================================
# Auto-Analysis Types
# ============================================================================


class ComputedQualityMetrics(BaseModel):
    """Computed trajectory quality metrics from auto-analysis."""

    smoothness_score: float = Field(ge=0.0, le=1.0)
    efficiency_score: float = Field(ge=0.0, le=1.0)
    jitter_metric: float = Field(ge=0.0)
    hesitation_count: int = Field(ge=0)
    correction_count: int = Field(ge=0)


class AutoQualityAnalysis(BaseModel):
    """Auto-analysis result for an episode."""

    episode_index: int = Field(ge=0)
    computed: ComputedQualityMetrics
    suggested_rating: int = Field(ge=1, le=5)
    confidence: float = Field(ge=0.0, le=1.0)
    flags: list[TrajectoryFlag] = Field(default_factory=list)

    model_config = {"use_enum_values": True}


# ============================================================================
# Annotation Summary Types
# ============================================================================


class AnnotationSummary(BaseModel):
    """Aggregated annotation metrics for a dataset."""

    dataset_id: str
    total_episodes: int = Field(ge=0)
    annotated_episodes: int = Field(ge=0)
    task_completeness_distribution: dict[str, int] = Field(default_factory=dict)
    quality_score_distribution: dict[int, int] = Field(default_factory=dict)
    anomaly_type_counts: dict[str, int] = Field(default_factory=dict)
