"""
YOLO11 object detection service.

Provides singleton model loading and frame-by-frame detection
for HDF5 episode data.
"""

import logging
import time
from collections.abc import Awaitable, Callable
from io import BytesIO
from typing import TYPE_CHECKING

from PIL import Image

from ..models.detection import (
    ClassSummary,
    Detection,
    DetectionRequest,
    DetectionResult,
    EpisodeDetectionSummary,
)

if TYPE_CHECKING:
    from ultralytics import YOLO

logger = logging.getLogger(__name__)


def _sanitize(value: object) -> str:
    """Sanitize a value for safe inclusion in log messages."""
    return str(value).replace("\n", "\\n").replace("\r", "\\r")


# COCO class names for YOLO models
ALLOWED_MODELS = {"yolo11n", "yolo11s", "yolo11m", "yolo11l", "yolo11x"}

COCO_CLASSES = [
    "person",
    "bicycle",
    "car",
    "motorcycle",
    "airplane",
    "bus",
    "train",
    "truck",
    "boat",
    "traffic light",
    "fire hydrant",
    "stop sign",
    "parking meter",
    "bench",
    "bird",
    "cat",
    "dog",
    "horse",
    "sheep",
    "cow",
    "elephant",
    "bear",
    "zebra",
    "giraffe",
    "backpack",
    "umbrella",
    "handbag",
    "tie",
    "suitcase",
    "frisbee",
    "skis",
    "snowboard",
    "sports ball",
    "kite",
    "baseball bat",
    "baseball glove",
    "skateboard",
    "surfboard",
    "tennis racket",
    "bottle",
    "wine glass",
    "cup",
    "fork",
    "knife",
    "spoon",
    "bowl",
    "banana",
    "apple",
    "sandwich",
    "orange",
    "broccoli",
    "carrot",
    "hot dog",
    "pizza",
    "donut",
    "cake",
    "chair",
    "couch",
    "potted plant",
    "bed",
    "dining table",
    "toilet",
    "tv",
    "laptop",
    "mouse",
    "remote",
    "keyboard",
    "cell phone",
    "microwave",
    "oven",
    "toaster",
    "sink",
    "refrigerator",
    "book",
    "clock",
    "vase",
    "scissors",
    "teddy bear",
    "hair drier",
    "toothbrush",
]


class DetectionService:
    """YOLO11 object detection service with caching."""

    def __init__(self) -> None:
        self._model: YOLO | None = None
        self._model_name: str = ""
        self._cache: dict[str, EpisodeDetectionSummary] = {}

    def _get_model(self, model_name: str = "yolo11n") -> "YOLO":
        """Load or return cached YOLO model."""
        if model_name not in ALLOWED_MODELS:
            raise ValueError(f"Model '{model_name}' is not supported")

        if self._model is None or self._model_name != model_name:
            try:
                from ultralytics import YOLO

                logger.info("Loading YOLO model: %s", _sanitize(model_name))
                self._model = YOLO(f"{model_name}.pt")
                self._model_name = model_name
                # Warmup with dummy inference
                import numpy as np

                dummy = np.zeros((640, 640, 3), dtype=np.uint8)
                self._model(dummy, verbose=False)
                logger.info("YOLO model loaded and warmed up")
            except ImportError:
                logger.error("ultralytics not installed. Run: uv sync --extra yolo")
                raise
        return self._model

    def _cache_key(self, dataset_id: str, episode_idx: int) -> str:
        """Generate cache key for detection results."""
        return f"{dataset_id}:{episode_idx}"

    def get_cached(self, dataset_id: str, episode_idx: int) -> EpisodeDetectionSummary | None:
        """Get cached detection results if available."""
        key = self._cache_key(dataset_id, episode_idx)
        return self._cache.get(key)

    def clear_cache(self, dataset_id: str, episode_idx: int) -> bool:
        """Clear cached detection results."""
        key = self._cache_key(dataset_id, episode_idx)
        if key in self._cache:
            del self._cache[key]
            return True
        return False

    async def detect_frame(
        self,
        image_bytes: bytes,
        frame_idx: int,
        confidence: float = 0.25,
        model_name: str = "yolo11n",
    ) -> DetectionResult:
        """Run detection on a single frame."""
        model = self._get_model(model_name)

        # Load image
        image = Image.open(BytesIO(image_bytes))
        logger.debug(
            "Frame %d: image size=%s, mode=%s, bytes=%d",
            int(frame_idx),
            image.size,
            image.mode,
            len(image_bytes),
        )

        # Run inference
        start_time = time.perf_counter()
        results = model(image, conf=confidence, verbose=False)
        elapsed_ms = (time.perf_counter() - start_time) * 1000

        logger.debug(
            "Frame %d: model returned %d result(s) in %.1fms",
            int(frame_idx),
            len(results) if results else 0,
            elapsed_ms,
        )

        # Parse results
        detections: list[Detection] = []
        if results and len(results) > 0:
            result = results[0]
            boxes = result.boxes
            logger.debug(
                "Frame %d: boxes=%s, num_boxes=%d",
                int(frame_idx),
                boxes is not None,
                len(boxes) if boxes is not None else 0,
            )

            if boxes is not None and len(boxes) > 0:
                for i in range(len(boxes)):
                    class_id = int(boxes.cls[i].item())
                    class_name = (
                        COCO_CLASSES[class_id]
                        if class_id < len(COCO_CLASSES)
                        else f"class_{class_id}"
                    )
                    conf = float(boxes.conf[i].item())
                    x1, y1, x2, y2 = boxes.xyxy[i].tolist()
                    detections.append(
                        Detection(
                            class_id=class_id,
                            class_name=class_name,
                            confidence=conf,
                            bbox=(x1, y1, x2, y2),
                        )
                    )
        else:
            logger.debug("Frame %d: no results from model", int(frame_idx))

        logger.debug("Frame %d: returning %d detections", int(frame_idx), len(detections))
        return DetectionResult(
            frame=frame_idx,
            detections=detections,
            processing_time_ms=elapsed_ms,
        )

    async def detect_episode(
        self,
        dataset_id: str,
        episode_idx: int,
        request: DetectionRequest,
        get_frame_image: Callable[[int], Awaitable[bytes | None]],
        total_frames: int,
    ) -> EpisodeDetectionSummary:
        """Run detection on episode frames."""
        logger.debug(
            "Starting detection: dataset=%s, episode=%d, frames=%d",
            _sanitize(dataset_id),
            int(episode_idx),
            total_frames,
        )

        # Determine frames to process
        frames_to_process = request.frames if request.frames else list(range(total_frames))
        logger.debug("Will process %d frames", len(frames_to_process))

        results_by_frame: list[DetectionResult] = []
        class_counts: dict[str, list[float]] = {}
        skipped_frames = 0

        for frame_idx in frames_to_process:
            try:
                image_bytes = await get_frame_image(frame_idx)
                if image_bytes is None:
                    skipped_frames += 1
                    if skipped_frames <= 3:
                        logger.debug("Frame %d: image_bytes is None", int(frame_idx))
                    continue

                if frame_idx == 0:
                    logger.debug("Frame 0: got %d bytes", len(image_bytes))

                result = await self.detect_frame(
                    image_bytes,
                    frame_idx,
                    confidence=request.confidence,
                    model_name=request.model,
                )

                if frame_idx == 0:
                    logger.debug("Frame 0: found %d detections", len(result.detections))

                results_by_frame.append(result)

                # Accumulate class statistics
                for det in result.detections:
                    if det.class_name not in class_counts:
                        class_counts[det.class_name] = []
                    class_counts[det.class_name].append(det.confidence)

            except Exception as e:
                logger.warning("Failed to process frame %d: %s", int(frame_idx), _sanitize(e))
                continue

        total_dets = sum(len(r.detections) for r in results_by_frame)
        logger.debug(
            "Complete: processed=%d, skipped=%d, detections=%d",
            len(results_by_frame),
            skipped_frames,
            total_dets,
        )

        # Build class summary
        class_summary = {
            name: ClassSummary(
                count=len(confs),
                avg_confidence=sum(confs) / len(confs) if confs else 0.0,
            )
            for name, confs in class_counts.items()
        }

        total_detections = sum(len(r.detections) for r in results_by_frame)

        summary = EpisodeDetectionSummary(
            total_frames=total_frames,
            processed_frames=len(results_by_frame),
            total_detections=total_detections,
            detections_by_frame=results_by_frame,
            class_summary=class_summary,
        )

        # Cache results
        key = self._cache_key(dataset_id, episode_idx)
        self._cache[key] = summary

        return summary


# Singleton instance
_detection_service: DetectionService | None = None


def get_detection_service() -> DetectionService:
    """Get the singleton detection service instance."""
    global _detection_service
    if _detection_service is None:
        _detection_service = DetectionService()
    return _detection_service
