workflow:
  name: lerobot-act-finetuning
  timeout:
    exec_timeout: 12h
  resources:
    default:
      gpu: 1
      cpu: 8
      memory: 48Gi
      storage: 80Gi
  tasks:
    - name: lerobot-train
      image: "{{ image }}"
      command:
        - /bin/bash
        - /tmp/entry.sh
      credentials:
        wandb:
          WANDB_API_KEY: wandb_api_key
        huggingface:
          HF_TOKEN: hf_token
      environment:
        DATASET_REPO_ID: "{{ dataset_repo_id }}"
        POLICY_TYPE: "{{ policy_type }}"
        OUTPUT_DIR: "{{ output_dir }}"
        JOB_NAME: "{{ job_name }}"
        POLICY_REPO_ID: "{{ policy_repo_id }}"
        WANDB_ENABLE: "{{ wandb_enable }}"
        WANDB_PROJECT: "{{ wandb_project }}"
        TRAINING_STEPS: "{{ training_steps }}"
        BATCH_SIZE: "{{ batch_size }}"
        EVAL_FREQ: "{{ eval_freq }}"
        SAVE_FREQ: "{{ save_freq }}"
        LEROBOT_VERSION: "{{ lerobot_version }}"
        MLFLOW_ENABLE: "{{ mlflow_enable }}"
        EXPERIMENT_NAME: "{{ experiment_name }}"
        REGISTER_CHECKPOINT: "{{ register_checkpoint }}"
        AZURE_SUBSCRIPTION_ID: "{{ azure_subscription_id }}"
        AZURE_RESOURCE_GROUP: "{{ azure_resource_group }}"
        AZUREML_WORKSPACE_NAME: "{{ azure_workspace_name }}"
        AZURE_AUTHORITY_HOST: "{{ azure_authority_host }}"
        MLFLOW_TRACKING_TOKEN_REFRESH_RETRIES: "{{ mlflow_token_refresh_retries }}"
        MLFLOW_HTTP_REQUEST_TIMEOUT: "{{ mlflow_http_request_timeout }}"
      files:
        - path: /tmp/entry.sh
          contents: |
            #!/bin/bash
            set -euo pipefail

            echo "=== LeRobot ACT Fine-tuning Workflow ==="
            echo "Dataset: ${DATASET_REPO_ID}"
            echo "Policy Type: ${POLICY_TYPE}"
            echo "Job Name: ${JOB_NAME}"
            echo "Output Dir: ${OUTPUT_DIR}"
            echo "Logging Backend: ${MLFLOW_ENABLE:-false}=true -> Azure ML | WANDB"

            # Install system dependencies
            echo "Installing system dependencies..."
            apt-get update -qq && apt-get install -y -qq \
              ffmpeg \
              libgl1-mesa-glx \
              libglib2.0-0 \
              git \
              build-essential \
              gcc \
              python3-dev \
              > /dev/null 2>&1

            # Install UV package manager
            echo "Installing UV package manager..."
            pip install --quiet uv

            # Install LeRobot and dependencies based on logging backend
            echo "Installing LeRobot ${LEROBOT_VERSION:-latest}..."
            if [[ "${MLFLOW_ENABLE:-false}" == "true" ]]; then
              echo "Installing Azure ML dependencies for MLflow logging..."
              if [[ -n "${LEROBOT_VERSION:-}" && "${LEROBOT_VERSION}" != "latest" ]]; then
                uv pip install "lerobot==${LEROBOT_VERSION}" huggingface-hub \
                  azure-identity azure-ai-ml azureml-mlflow "mlflow>=2.8.0" --system
              else
                uv pip install lerobot huggingface-hub \
                  azure-identity azure-ai-ml azureml-mlflow "mlflow>=2.8.0" --system
              fi
            else
              if [[ -n "${LEROBOT_VERSION:-}" && "${LEROBOT_VERSION}" != "latest" ]]; then
                uv pip install "lerobot==${LEROBOT_VERSION}" wandb huggingface-hub --system
              else
                uv pip install lerobot wandb huggingface-hub --system
              fi
            fi

            # Authenticate with HuggingFace Hub
            echo "Authenticating with HuggingFace Hub..."
            if [[ -n "${HF_TOKEN:-}" ]]; then
              # Use Python API for auth (works across all huggingface-hub versions)
              python3 -c "from huggingface_hub import login; login(token='${HF_TOKEN}', add_to_git_credential=False)"
            else
              echo "Warning: HF_TOKEN not set, skipping HuggingFace authentication"
            fi

            # Configure logging backend
            if [[ "${MLFLOW_ENABLE:-false}" == "true" ]]; then
              echo "Configuring Azure ML MLflow tracking..."

              # Validate required Azure environment variables
              if [[ -z "${AZURE_SUBSCRIPTION_ID:-}" || -z "${AZURE_RESOURCE_GROUP:-}" || -z "${AZUREML_WORKSPACE_NAME:-}" ]]; then
                echo "Error: Azure ML requires AZURE_SUBSCRIPTION_ID, AZURE_RESOURCE_GROUP, and AZUREML_WORKSPACE_NAME"
                exit 1
              fi

              # Bootstrap Azure ML and configure MLflow
              python3 << 'BOOTSTRAP_SCRIPT'
            import os
            import sys

            try:
                import mlflow
                from azure.ai.ml import MLClient
                from azure.identity import DefaultAzureCredential

                print("[INFO] Initializing Azure ML connection...")

                credential = DefaultAzureCredential(
                    managed_identity_client_id=os.environ.get("AZURE_CLIENT_ID"),
                    authority=os.environ.get("AZURE_AUTHORITY_HOST"),
                )

                client = MLClient(
                    credential=credential,
                    subscription_id=os.environ["AZURE_SUBSCRIPTION_ID"],
                    resource_group_name=os.environ["AZURE_RESOURCE_GROUP"],
                    workspace_name=os.environ["AZUREML_WORKSPACE_NAME"],
                )

                workspace = client.workspaces.get(os.environ["AZUREML_WORKSPACE_NAME"])
                tracking_uri = workspace.mlflow_tracking_uri

                if not tracking_uri:
                    print("[ERROR] Azure ML workspace does not expose MLflow tracking URI")
                    sys.exit(1)

                mlflow.set_tracking_uri(tracking_uri)

                # Set experiment name
                experiment_name = os.environ.get("EXPERIMENT_NAME") or f"lerobot-{os.environ.get('POLICY_TYPE', 'act')}-{os.environ.get('JOB_NAME', 'training')}"
                mlflow.set_experiment(experiment_name)

                # Enable autolog for PyTorch
                mlflow.autolog(log_models=False, log_input_examples=False)

                print(f"[INFO] MLflow tracking URI: {tracking_uri}")
                print(f"[INFO] MLflow experiment: {experiment_name}")
                print("[INFO] MLflow autolog enabled for PyTorch")

                # Write tracking URI to file for post-training checkpoint registration
                with open("/tmp/mlflow_config.env", "w") as f:
                    f.write(f"MLFLOW_TRACKING_URI={tracking_uri}\n")
                    f.write(f"MLFLOW_EXPERIMENT_NAME={experiment_name}\n")

            except Exception as e:
                print(f"[ERROR] Failed to configure Azure ML: {e}")
                sys.exit(1)
            BOOTSTRAP_SCRIPT

              # Source MLflow config for later use
              if [[ -f /tmp/mlflow_config.env ]]; then
                export $(cat /tmp/mlflow_config.env | xargs)
              fi
            else
              # WANDB authentication
              if [[ -n "${WANDB_API_KEY:-}" ]]; then
                echo "WANDB authentication configured via environment"
              else
                echo "Warning: WANDB_API_KEY not set"
              fi
            fi

            # Build training arguments
            # This is a Bash array definition embedded in YAML.
            # In Bash arrays, elements are separated by whitespace (newlines here),
            # not commas. Each line inside the parentheses is a separate array element.
            # The array will be expanded as individual arguments when passed to a command.
            train_args=(
              --dataset.repo_id="${DATASET_REPO_ID}"
              --policy.type="${POLICY_TYPE}"
              --output_dir="${OUTPUT_DIR}"
              --job_name="${JOB_NAME}"
              --policy.device=cuda
            )

            # Configure logging in training arguments
            if [[ "${MLFLOW_ENABLE:-false}" == "true" ]]; then
              # Disable WANDB when using MLflow
              train_args+=(--wandb.enable=false)
            elif [[ "${WANDB_ENABLE:-true}" == "true" ]]; then
              train_args+=(--wandb.enable=true)
              if [[ -n "${WANDB_PROJECT:-}" ]]; then
                train_args+=(--wandb.project="${WANDB_PROJECT}")
              fi
            else
              train_args+=(--wandb.enable=false)
            fi

            if [[ -n "${POLICY_REPO_ID:-}" ]]; then
              train_args+=(--policy.repo_id="${POLICY_REPO_ID}")
            else
              # Auto-detect HF username and generate default repo_id
              hf_user=$(python3 -c "from huggingface_hub import whoami; print(whoami()['name'])" 2>/dev/null || echo "")
              if [[ -n "$hf_user" ]]; then
                default_repo="${hf_user}/${JOB_NAME}"
                echo "Auto-derived policy.repo_id: ${default_repo}"
                train_args+=(--policy.repo_id="${default_repo}")
              else
                echo "Warning: Cannot derive policy.repo_id (no HF auth). Training may fail."
              fi
            fi

            if [[ -n "${TRAINING_STEPS:-}" ]]; then
              train_args+=(--steps="${TRAINING_STEPS}")
            fi

            if [[ -n "${BATCH_SIZE:-}" ]]; then
              train_args+=(--batch_size="${BATCH_SIZE}")
            fi

            if [[ -n "${EVAL_FREQ:-}" ]]; then
              train_args+=(--eval_freq="${EVAL_FREQ}")
            fi

            if [[ -n "${SAVE_FREQ:-}" ]]; then
              train_args+=(--save_freq="${SAVE_FREQ}")
            fi

            echo "Starting LeRobot training..."
            echo "Command: lerobot-train ${train_args[*]}"

            # Run training with MLflow metric capture if enabled
            if [[ "${MLFLOW_ENABLE:-false}" == "true" ]]; then
              # Use Python wrapper to capture metrics and log to MLflow
              python3 << TRAIN_WRAPPER
            import os
            import re
            import signal
            import subprocess
            import sys
            import time
            from pathlib import Path

            import mlflow

            train_args = """${train_args[*]}""".split()
            cmd = ["lerobot-train"] + train_args

            print(f"[MLflow] Starting run with command: {' '.join(cmd)}")

            # Regex to parse LeRobot log lines like:
            # step:200 smpl:2K ep:4 epch:0.31 loss:6.938 grdn:155.563 lr:1.0e-05 updt_s:0.324 data_s:0.011
            log_pattern = re.compile(
                r"step:(\d+\.?\d*K?)\s+"
                r"smpl:(\d+\.?\d*K?)\s+"
                r"ep:(\d+\.?\d*K?)\s+"
                r"epch:([\d.]+)\s+"
                r"loss:([\d.]+)\s+"
                r"grdn:([\d.]+)\s+"
                r"lr:([\d.e+-]+)\s+"
                r"updt_s:([\d.]+)\s+"
                r"data_s:([\d.]+)"
            )

            def parse_k_value(val: str) -> float:
                """Parse values like '2K' to 2000."""
                if val.endswith("K"):
                    return float(val[:-1]) * 1000
                return float(val)

            # Track checkpoints that have been uploaded
            uploaded_checkpoints = set()
            output_dir = Path(os.environ.get("OUTPUT_DIR", "/workspace/outputs/train"))
            last_checkpoint_check = 0
            CHECKPOINT_CHECK_INTERVAL = 60  # Check for new checkpoints every 60 seconds

            def upload_checkpoint_via_mlflow(run, checkpoint_path: Path, checkpoint_name: str) -> bool:
                """Upload checkpoint as MLflow artifact and register as a model."""
                try:
                    job_name = os.environ.get("JOB_NAME", "lerobot-training")
                    policy_type = os.environ.get("POLICY_TYPE", "act")
                    register_name = os.environ.get("REGISTER_CHECKPOINT", "") or job_name
                    model_name = register_name.replace("_", "-")

                    artifact_path = f"checkpoints/{checkpoint_name}"
                    mlflow.log_artifacts(str(checkpoint_path), artifact_path)
                    model_uri = f"runs:/{run.info.run_id}/{artifact_path}"

                    mlflow.set_tag(f"checkpoint_{checkpoint_name}_artifact", artifact_path)

                    result = mlflow.register_model(
                        model_uri=model_uri,
                        name=model_name,
                        tags={
                            "framework": "lerobot",
                            "policy_type": policy_type,
                            "job_name": job_name,
                            "checkpoint": checkpoint_name,
                            "source": "osmo-lerobot-training",
                        },
                    )
                    print(f"[MLflow] Checkpoint registered: {result.name} v{result.version}")
                    return True
                except Exception as e:
                    print(f"[MLflow] Failed to register checkpoint {checkpoint_name}: {e}")
                    return False

            def upload_new_checkpoints(run):
                """Upload any new checkpoints via MLflow."""
                global uploaded_checkpoints
                checkpoints_dir = output_dir / "checkpoints"
                if not checkpoints_dir.exists():
                    return

                for ckpt_dir in checkpoints_dir.iterdir():
                    if ckpt_dir.is_dir() and ckpt_dir.name not in uploaded_checkpoints:
                        pretrained_dir = ckpt_dir / "pretrained_model"
                        if pretrained_dir.exists() and (pretrained_dir / "model.safetensors").exists():
                            print(f"[MLflow] Uploading checkpoint: {ckpt_dir.name}")
                            if upload_checkpoint_via_mlflow(run, pretrained_dir, ckpt_dir.name):
                                uploaded_checkpoints.add(ckpt_dir.name)
                                print(f"[MLflow] Checkpoint {ckpt_dir.name} uploaded successfully")

            with mlflow.start_run(run_name=os.environ.get("JOB_NAME", "lerobot-training")) as run:
                print(f"[MLflow] Run ID: {run.info.run_id}")

                # Log parameters
                mlflow.log_params({
                    "dataset_repo_id": os.environ.get("DATASET_REPO_ID", ""),
                    "policy_type": os.environ.get("POLICY_TYPE", "act"),
                    "job_name": os.environ.get("JOB_NAME", ""),
                    "policy_repo_id": os.environ.get("POLICY_REPO_ID", ""),
                    "training_steps": os.environ.get("TRAINING_STEPS", "100000"),
                    "batch_size": os.environ.get("BATCH_SIZE", "8"),
                    "save_freq": os.environ.get("SAVE_FREQ", "5000"),
                })

                # Run training and capture output
                process = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1,
                )

                # Handle graceful shutdown
                def signal_handler(signum, frame):
                    print(f"[MLflow] Received signal {signum}, saving checkpoints...")
                    upload_new_checkpoints(run)
                    process.terminate()

                signal.signal(signal.SIGTERM, signal_handler)
                signal.signal(signal.SIGINT, signal_handler)

                for line in process.stdout:
                    print(line, end="", flush=True)

                    # Parse and log metrics
                    match = log_pattern.search(line)
                    if match:
                        step = int(parse_k_value(match.group(1)))
                        metrics = {
                            "samples": parse_k_value(match.group(2)),
                            "episodes": parse_k_value(match.group(3)),
                            "epoch": float(match.group(4)),
                            "loss": float(match.group(5)),
                            "grad_norm": float(match.group(6)),
                            "learning_rate": float(match.group(7)),
                            "update_time_s": float(match.group(8)),
                            "data_time_s": float(match.group(9)),
                        }
                        mlflow.log_metrics(metrics, step=step)

                        # Periodically check for and upload new checkpoints
                        current_time = time.time()
                        if current_time - last_checkpoint_check > CHECKPOINT_CHECK_INTERVAL:
                            last_checkpoint_check = current_time
                            upload_new_checkpoints(run)

                process.wait()

                # Final checkpoint upload
                print("[MLflow] Uploading final checkpoints...")
                upload_new_checkpoints(run)

                # Log final model artifact path
                mlflow.log_param("output_dir", str(output_dir))

                if process.returncode != 0:
                    mlflow.set_tag("training_status", "failed")
                    print(f"[MLflow] Training failed with return code: {process.returncode}")
                    sys.exit(process.returncode)
                else:
                    mlflow.set_tag("training_status", "completed")

            print("[MLflow] Run completed")
            TRAIN_WRAPPER
            else
              # Run without MLflow wrapper
              lerobot-train "${train_args[@]}"
            fi

            echo "=== Training Complete ==="

            # Post-training: Register checkpoint to Azure ML if enabled
            if [[ "${MLFLOW_ENABLE:-false}" == "true" && -n "${REGISTER_CHECKPOINT:-}" ]]; then
              echo "=== Registering Checkpoint to Azure ML ==="

              python3 << 'REGISTER_SCRIPT'
            import os
            import sys
            from pathlib import Path

            try:
                import mlflow

                output_dir = Path(os.environ["OUTPUT_DIR"])
                model_name = os.environ["REGISTER_CHECKPOINT"]
                job_name = os.environ.get("JOB_NAME", "lerobot-training")
                policy_type = os.environ.get("POLICY_TYPE", "act")

                # Find the latest checkpoint directory
                checkpoint_dirs = sorted(output_dir.glob("checkpoints/*"), key=lambda p: p.stat().st_mtime, reverse=True)
                if not checkpoint_dirs:
                    pretrained_dir = output_dir / "pretrained_model"
                    if pretrained_dir.exists():
                        checkpoint_path = pretrained_dir
                        checkpoint_name = "last"
                    else:
                        print(f"[WARNING] No checkpoints found in {output_dir}")
                        sys.exit(0)
                else:
                    checkpoint_path = checkpoint_dirs[0] / "pretrained_model"
                    checkpoint_name = checkpoint_dirs[0].name
                    if not checkpoint_path.exists():
                        checkpoint_path = checkpoint_dirs[0]

                print(f"[INFO] Registering checkpoint from: {checkpoint_path}")
                print(f"[INFO] Model name: {model_name}")

                # Read tracking URI from bootstrap config
                tracking_uri = os.environ.get("MLFLOW_TRACKING_URI", "")
                if tracking_uri:
                    mlflow.set_tracking_uri(tracking_uri)

                experiment_name = os.environ.get("MLFLOW_EXPERIMENT_NAME", "") or f"lerobot-{policy_type}-{job_name}"
                mlflow.set_experiment(experiment_name)

                with mlflow.start_run(run_name=f"{job_name}-register") as run:
                    artifact_path = f"checkpoints/{checkpoint_name}"
                    mlflow.log_artifacts(str(checkpoint_path), artifact_path)
                    model_uri = f"runs:/{run.info.run_id}/{artifact_path}"

                    result = mlflow.register_model(
                        model_uri=model_uri,
                        name=model_name,
                        tags={
                            "framework": "lerobot",
                            "policy_type": policy_type,
                            "job_name": job_name,
                            "checkpoint": checkpoint_name,
                            "source": "osmo-workflow",
                        },
                    )
                    print(f"[INFO] Model registered: {result.name} (version: {result.version})")

            except Exception as e:
                print(f"[ERROR] Failed to register checkpoint: {e}")
                import traceback
                traceback.print_exc()
                sys.exit(0)
            REGISTER_SCRIPT

              echo "=== Checkpoint Registration Complete ==="
            fi

default-values:
  image: pytorch/pytorch:2.4.1-cuda12.4-cudnn9-runtime
  dataset_repo_id: ""
  policy_type: act
  output_dir: /workspace/outputs/train
  job_name: lerobot-act-training
  policy_repo_id: ""
  wandb_enable: "true"
  wandb_project: lerobot-training
  training_steps: ""
  batch_size: ""
  eval_freq: ""
  save_freq: "5000"
  lerobot_version: ""
  mlflow_enable: "false"
  experiment_name: ""
  register_checkpoint: ""
  azure_subscription_id: ""
  azure_resource_group: ""
  azure_workspace_name: ""
  azure_authority_host: https://login.microsoftonline.com
  mlflow_token_refresh_retries: "3"
  mlflow_http_request_timeout: "60"
